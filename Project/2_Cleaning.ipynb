{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PBoDecfsAsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "443a62c3-7645-47b0-d82d-9e04fad8d5c8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import string\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYp9rGKmKUrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46be7c6e-fcb1-4b6f-efb2-0c869f32c43c"
      },
      "source": [
        "# Скачаем файлы базы\n",
        "!rm -rf /content/sberbank_data_analysis/\n",
        "!git clone https://github.com/fish34/sberbank_data_analysis.git\n",
        "!unzip /content/sberbank_data_analysis/Project/courses.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sberbank_data_analysis'...\n",
            "remote: Enumerating objects: 264, done.\u001b[K\n",
            "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 264 (delta 71), reused 103 (delta 44), pack-reused 97\u001b[K\n",
            "Receiving objects: 100% (264/264), 58.43 MiB | 11.68 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n",
            "Archive:  /content/sberbank_data_analysis/Project/courses.zip\n",
            "  inflating: courses.csv             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4wURUyrB1Qa"
      },
      "source": [
        "df_courses=pd.read_csv(\"/content/courses.csv\",index_col=0)\n",
        "df_courses_cleaned=df_courses.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDZUBrIeak5m"
      },
      "source": [
        "#Разобьем на токены, проведем лемматизацию (т.к. в отличие от стемминга всегда возвращает корректное слово)\n",
        "#уберем пунктуацию, ссылки по тексту, уберем символы, не являющиеся буквенными, а так же не из списка стоп - слов.\n",
        "def clean_words(text):\n",
        "  wnl=WordNetLemmatizer()\n",
        "  filtered=re.sub(r'(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-?=%.]+','',text)\n",
        "  tokens=word_tokenize(filtered)\n",
        "  tokens=[word.lower() for word in tokens]\n",
        "  tokens = [word for word in tokens if not word in stop_words]\n",
        "  tokens=[word.replace(\"-\",\" \") for word in tokens]\n",
        "  words=[wnl.lemmatize(word) for word in tokens]\n",
        "  table=str.maketrans('','',string.punctuation)\n",
        "  stripped=[word.translate(table) for word in tokens]\n",
        "  words = [word for word in stripped if word.isalpha()]\n",
        "  return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmStByAtA9Tb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "33f2e1a8-682c-43a3-cdd7-c74aebe56acc"
      },
      "source": [
        "df_courses_cleaned['descr']=df_courses['descr'].apply(lambda x : clean_words(x))\n",
        "df_courses_cleaned"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>descr</th>\n",
              "      <th>marks</th>\n",
              "      <th>raiting</th>\n",
              "      <th>url</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Introduction to Big Data</td>\n",
              "      <td>[interested, increasing, knowledge, big, data, landscape, course, new, data, science, interested...</td>\n",
              "      <td>9666</td>\n",
              "      <td>4.6</td>\n",
              "      <td>https://www.coursera.org/learn/big-data-introduction</td>\n",
              "      <td>big data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Big Data Essentials: HDFS, MapReduce and Spark RDD</td>\n",
              "      <td>[ever, heard, technologies, hdfs, mapreduce, spark, always, wanted, learn, new, tools, missed, c...</td>\n",
              "      <td>528</td>\n",
              "      <td>4.0</td>\n",
              "      <td>https://www.coursera.org/learn/big-data-essentials</td>\n",
              "      <td>big data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Big Data, Artificial Intelligence, and Ethics</td>\n",
              "      <td>[course, gives, context, experience, two, major, catalyzers, computational, science, revolution,...</td>\n",
              "      <td>317</td>\n",
              "      <td>4.6</td>\n",
              "      <td>https://www.coursera.org/learn/big-data-ai-ethics</td>\n",
              "      <td>big data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Introduction to Data Engineering</td>\n",
              "      <td>[course, introduces, core, concepts, processes, tools, need, know, order, get, foundational, kno...</td>\n",
              "      <td>57</td>\n",
              "      <td>4.6</td>\n",
              "      <td>https://www.coursera.org/learn/introduction-to-data-engineering</td>\n",
              "      <td>big data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data-driven Decision Making</td>\n",
              "      <td>[welcome, decision, making, course, ll, get, introduction, data, analytics, role, business, deci...</td>\n",
              "      <td>5451</td>\n",
              "      <td>4.6</td>\n",
              "      <td>https://www.coursera.org/learn/decision-making</td>\n",
              "      <td>big data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3210</th>\n",
              "      <td>High Level Biocontainment for Healthcare Facilities</td>\n",
              "      <td>[goal, course, equip, learners, safely, care, patient, infected, pathogen, requiring, biocontain...</td>\n",
              "      <td>82</td>\n",
              "      <td>4.7</td>\n",
              "      <td>https://www.coursera.org/learn/biocontainment</td>\n",
              "      <td>system administration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3211</th>\n",
              "      <td>U101: Understanding College and College Life</td>\n",
              "      <td>[college, confusing, intimidating, help, admitted, college, nervous, next, step, life, might, lo...</td>\n",
              "      <td>390</td>\n",
              "      <td>4.6</td>\n",
              "      <td>https://www.coursera.org/learn/college-life</td>\n",
              "      <td>system administration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3212</th>\n",
              "      <td>Researcher Management and Leadership Training</td>\n",
              "      <td>[course, early, career, researchers, mentors, believe, modern, scientific, careers, require, man...</td>\n",
              "      <td>153</td>\n",
              "      <td>4.9</td>\n",
              "      <td>https://www.coursera.org/learn/researcher-management-leadership-training</td>\n",
              "      <td>system administration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3213</th>\n",
              "      <td>Foundations for Global Health Responders</td>\n",
              "      <td>[around, world, increasingly, socially, economically, interdependent, health, one, side, globe, ...</td>\n",
              "      <td>23</td>\n",
              "      <td>4.6</td>\n",
              "      <td>https://www.coursera.org/learn/ghresponder</td>\n",
              "      <td>system administration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3214</th>\n",
              "      <td>Easing the burden of obesity, diabetes and cardiovascular disease</td>\n",
              "      <td>[course, multidisciplinary, nature, aims, equip, global, audience, interested, lay, people, peop...</td>\n",
              "      <td>107</td>\n",
              "      <td>4.6</td>\n",
              "      <td>https://www.coursera.org/learn/easing-the-burden-of-obesity-diabetes-cvd</td>\n",
              "      <td>system administration</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3215 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                  title  ...              direction\n",
              "0                                              Introduction to Big Data  ...               big data\n",
              "1                    Big Data Essentials: HDFS, MapReduce and Spark RDD  ...               big data\n",
              "2                         Big Data, Artificial Intelligence, and Ethics  ...               big data\n",
              "3                                      Introduction to Data Engineering  ...               big data\n",
              "4                                           Data-driven Decision Making  ...               big data\n",
              "...                                                                 ...  ...                    ...\n",
              "3210                High Level Biocontainment for Healthcare Facilities  ...  system administration\n",
              "3211                       U101: Understanding College and College Life  ...  system administration\n",
              "3212                      Researcher Management and Leadership Training  ...  system administration\n",
              "3213                           Foundations for Global Health Responders  ...  system administration\n",
              "3214  Easing the burden of obesity, diabetes and cardiovascular disease  ...  system administration\n",
              "\n",
              "[3215 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AygvasYy-JZS"
      },
      "source": [
        "df_courses_cleaned.to_csv(\"courses_cleaned.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXdaeC0WyNvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f583d63a-324b-41c5-cd67-d8ad2e4258a1"
      },
      "source": [
        "!zip courses_cleaned.zip courses_cleaned.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: courses_cleaned.csv (deflated 75%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}